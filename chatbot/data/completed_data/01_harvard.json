{
    "data": [
        {
            "id": "test1",
            "text": "금일의 논의는 검색 문제로부터 시작한다. 컴퓨터 혹은 어떤 에이전트가 특정 환경 내에서 해결책을 탐색해야 하는 상황에 대한 문제이다. 다양한 형식의 문제들이 있으며, 예를 들어 15 퍼즐과 같이 타일을 올바른 순서로 배열해야 하는 문제 등이 포함된다. 이러한 검색 문제를 해결하기 위해서는 몇 가지 용어를 도입할 필요가 있다. 첫째로, '에이전트'는 자신의 환경을 인식하고 그에 따라 행동할 수 있는 실체를 지칭한다. 예를 들어, 차량 내비게이션의 경우 에이전트는 목적지에 도달하기 위해 어떤 행동을 취해야 할지를 결정하는 차량의 대표일 수 있다. 다음으로, '상태'는 에이전트와 그 환경의 특정 구성을 의미한다. '초기 상태'는 검색 알고리즘이 시작되는 지점이며, '행동'은 주어진 상태에서 수행할 수 있는 선택지들을 말한다. '전이 모델'은 특정 행동을 취했을 때 도달하게 되는 새로운 상태를 설명한다. 이러한 구성을 통해 '상태 공간'이 형성되며, 문제 해결을 위한 경로 탐색이 가능해진다. 목적지에 도달했는지를 판단하는 '목표 테스트'와 경로의 비용을 계산하는 '경로 비용 함수' 역시 필요하다. 경로 비용은 최적의 해결책을 찾기 위해 최소화 되어야 한다. 이처럼 검색 문제는 초기 상태에서 출발하여 가능한 행동들을 통해 목표 상태에 도달하고, 이 과정에서 발생하는 비용을 최소화하는 해결책을 찾는 과정을 요구한다.",
            "timestamp": "000313",
            "summarization": "에이에이전트는 자신의 환경을 인식하고 그에 따라 행동하는 실체로 차량 내비게이션의 경우 에이전트는 목적지에 도달하기 위해 어떤 행동을 취해야 할지를 결정하는 차량의 대표일 수 있는데 초기에 출발하여 가능한 행동들을 통해 목표 상태에 도달하고, 이 과정에서 발생하는 비용을 최소화하는 해결책을 찾는 과정을 요구하는데 초기에 출발하여 가능한 행동들을 통해 목표 상태에 도달하고, 이 과정에서 발생하는 비용을 최소화하는 해결책을 찾는 과정을 요구한다."
        },
        {
            "id": "test2",
            "text": "본 문서는 인공지능과 Python에 대한 서론 강의에 대한 내용을 담고 있다. 강사인 Brian U는 과정에서 인공지능의 기초가 되는 아이디어, 기술, 알고리즘들을 탐색할 예정임을 밝혔다. 인공지능은 넓은 범위의 기술을 포함하며, 사진 속 사람의 얼굴 인식, 인간보다 더 나은 게임 수행, 휴대폰과 대화 시 인간 언어 이해 및 반응 등이 이에 해당한다. 강의는 이러한 인공지능을 가능하게 하는 아이디어에 초점을 맞출 것이다. 첫 번째 주제로는 문제 해결을 위한 AI의 탐색 능력, 이어서 AI가 정보를 알고 이를 바탕으로 추론을 도출하는 '지식' 파트가 다뤄진다. 불확실성에 대한 토의를 통해 컴퓨터가 확률을 기반으로 불확실한 사건을 처리하는 방법을 탐구하고, 이후 최적화 문제 해결 방법에 대해 논의한다. 머신 러닝 섹션에서는 데이터와 경험 학습을 통해 컴퓨터가 보다 능숙하게 작업을 수행하는 방식을 살펴본다. 이 과정에서는 컴퓨터가 과거 데이터와 경험으로부터 학습하는 이메일 스팸 필터링 예시를 포함한다. 인간 지능에서 영감을 받은 컴퓨터 프로그램의 구조, 즉 신경망 작성 방법도 소개한다. 마지막으로, 자연 언어 처리가 인공지능에서 어떻게 작동하는지, 컴퓨터가 일상적으로 사용하는 인간 언어를 이해하는 데 따르는 도전 과제를 설명한다.",
            "timestamp": "000513",
            "summarization": "강사인 Brian U는 사진 속 사람의 얼굴 인식, 인간보다 더 나은 게임 수행, 휴대폰과 대화 시 인간 언어 이해 및 반응 등 인공지능을 가능하게 하는 아이디어에 초점을 맞춰 인공지능의 기초가 되는 아이디어, 기술, 알고리즘들을 탐색할 예정이다."
        },
        {
            "id": "test3",
            "text": "최종 목표는 초기 상태에서 목표 상태로 이동하는 일련의 행동이 포함된 해결책을 찾는 것이며, 이상적으로는 모든 가능한 해결책 중 가장 낮은 경로 비용을 가진 최적의 해결책을 찾는 것이다. 문제를 해결하기 위해서는 컴퓨터가 문제에 대한 다양한 데이터를 표현할 수 있어야 하는데, 이러한 데이터는 노드라는 데이터 구조를 사용하여 구성된다. 각각의 노드는 현재 상태, 부모 상태, 부모로부터 현재 상태로 이동하기 위해 취한 행동, 그리고 초기 상태로부터 현재 상태까지 도달하는 데 걸린 시간을 나타내는 경로 비용을 추적한다. 문제 해결 방법에는 초기 상태를 포함하는 프런티어로 시작하여, 프런티어가 비어 있지 않은 경우 계속해서 노드를 제거하고, 해당 노드가 목표인지를 확인한 뒤 목표가 아니면 노드를 확장하여 프런티어에 추가하는 과정을 반복하는 검색 알고리즘이 포함된다. 만약 양방향 이동이 가능하여 무한 루프에 빠질 가능성이 있는 경우, 이미 탐색한 상태를 기록하여 중복을 방지하는 개선된 접근 방식을 사용한다. 이러한 개선된 방식은 프런티어에 새로운 노드를 추가하기 전에 이미 프런티어나 탐색한 상태 집합에 있는지를 확인한다. 프런티어에서 노드를 제거하는 방식, 즉 노드를 추가하고 제거하는 순서를 결정하는 것은 알고리즘의 효율성에 중요한 요소이다.",
            "timestamp": "001013",
            "summarization": "초는 상태를 포함하는 프런티어로 시작해  비어 있지 않은 경우 계속 노드를 제거하고 해당 노드가 목표인지 확인한 뒤 목표가 아니면 노드를 확장하여 프런티어에 추가하는 과정을 반복하는 검색 알고리즘과 양방향 이동이 가능하여 무한 루프에 빠질 가능성이 있는 경우, 이미 탐색한 상태를 기록하여 중복을 방지하는 개선된 접근 방식을 사용한다."
        },
        {
            "id": "test4",
            "text": "스택은 자료 구조 중 하나로, 후입선출(Last In, First Out; LIFO) 방식을 따른다는 점에서 특징을 가진다. 이 방식에 따르면, 가장 마지막에 추가된 요소가 가장 먼저 제거된다. 예를 들어, A에서 E로의 경로를 찾는 문제에 스택 기반 접근 방식을 적용할 경우, 처음에는 A에서 시작하여 탐색 대상으로 추가한다. A를 탐색한 후, A에서 갈 수 있는 B를 탐색 대상에 추가한 다음, B에서 갈 수 있는 C와 D를 차례로 추가한다. 여기서, 가장 마지막에 추가된 D를 다음 탐색 대상으로 선택하게 되며, D에서 갈 수 있는 F를 탐색 대상에 추가한다. 스택의 후입선출 방식에 따라, F를 다음에 탐색하게 되고, F에서 더 이상 갈 곳이 없을 때 C가 탐색 대상이 된다. C에서 E로 갈 수 있음을 발견한 후 E를 탐색 대상에 추가하고, E를 탐색함으로써 문제를 해결한다. 이 과정에서, A에서 시작하여 B, D, F 순으로 탐색을 진행하다가, 더 이상 진행할 수 없게 되면 C와 그 다음으로 E로 방향을 전환한다. 이러한 방식으로 깊은 부분을 우선 탐색하는 것을 깊이 우선 탐색(Depth First Search; DFS)이라 부르며, 탐색 트리에서 가능한 한 깊숙이 탐색을 진행하다가 막다른 길에 도달하면 다른 경로를 시도하는 방식으로 작동한다.",
            "timestamp": "002013",
            "summarization": "스택은 후입선출(Last In, First Out; LIFO) 방식으로 깊은 부분을 우선 탐색하는 것을 깊이 우선 탐색(Depth First Search; DFS)이라 부르며, 탐색 트리에서 가능한 한 깊숙이 탐색을 진행하다가 막다른 길에 도달하면 다른 경로를 시도하는 방식으로 작동한다."
        },
        {
            "id": "test5",
            "text": "탐색 알고리즘의 효율성은 주어진 문제를 푸는 데 사용되는 조건과 구현 방식에 따라 달라집니다. 특히, 깊이 우선 탐색(DFS)와 너비 우선 탐색(BFS)은 탐색 전략 면에서 핵심적인 차이를 보입니다. 깊이 우선 탐색은 가장 깊은 노드부터 탐색하는 방식이며, 스택을 사용하여 가장 최근에 추가된 항목부터 탐색합니다. 반면, 너비 우선 탐색은 가장 얕은 노드부터 탐색하며, 큐를 사용하여 가장 먼저 추가된 항목부터 탐색하는 방식으로 동작합니다. 이러한 차이로 인해 각각의 탐색 방식은 문제 해결 시 다른 경로와 성능을 나타냅니다.  깊이 우선 탐색은 단일 경로를 따라 끝까지 탐색하고, 막히면 마지막 분기점으로 돌아가 다른 경로를 탐색합니다. 이 방식은 미로 같은 문제에서는 경로를 찾을 수 있지만, 항상 최적의 해결책을 제시하는 것은 아닙니다. 반면, 너비 우선 탐색은 초기 상태로부터 일정 거리에 있는 모든 노드를 차례대로 탐색하며, 이는 미로 문제에서 보다 최적의 해결책을 찾을 가능성을 높입니다. 그러나 너비 우선 탐색이 항상 깊이 우선 탐색보다 낫다고 할 수 없는 이유는, 너비 우선 탐색은 탐색 과정에서 많은 상태를 확인해야 하기 때문에 메모리 사용량이 늘어날 수 있기 때문입니다.  각각의 탐색 방식은 문제의 종류와 조건에 따라 유용하게 적용될 수 있습니다. 예를 들어, 깊이 우선 탐색은 탐색 과정에서 사용하는 메모리의 양을 줄일 수 있는 경우에 유리하며, 너비 우선 탐색은 최적의 해결책을 찾는 것이 중요한 경우에 적합합니다.  결과적으로 탐색 알고리즘의 선택은 문제에 대한 구체적인 요구사항과 제한 조건을 고려하여 결정되어야 합니다. 이를 위해 알고리즘이 내부적으로 사용하는 데이터 구조(스택 또는 큐)를 변경하거나, 더 고급의 탐색 전략을 적용하여 알고리즘의 효율성을 향상시킬 수 있습니다.",
            "timestamp": "001813",
            "summarization": "많은색 탐색(DFS)와 너비 우선 탐색(BFS)은 탐색 전략 면에서 핵심적인 차이를 보이나  깊이 우선 탐색은 가장 깊은 노드부터 탐색하는 방식이며, 스택을 사용하여 가장 최근에 추가된 항목부터 탐색하는 반면, 너비 우선 탐색은 초기 상태로부터 일정 거리에 있는 모든 노드를 차례대로 탐색하며, 이는 미로 문제에서 보다 최적의 해결책을 찾을 가능성을 높다."
        },
        {
            "id": "test6",
            "text": "탐색 알고리즘에는 다양한 유형이 있으며, 특히 탐욕적 최선 우선 탐색(Greedy Best First Search, GBFS)에 대해 논의한다. 해당 알고리즘은 DFS(깊이 우선 탐색)나 BFS(너비 우선 탐색)와 달리 목표에 가장 가까운 노드를 우선 확장한다. 이 알고리즘은 목표까지의 정확한 거리를 알지 못하며, 대신 목표까지의 예상 거리를 제공하는 휴리스틱 함수, 즉 h(n)을 사용하여 추정한다. 미로 해결 알고리즘에서 휴리스틱 함수는 맨해튼 거리를 사용하여 각 셀로부터 목표까지의 거리를 추정한다. GBFS는 이 휴리스틱을 기반으로 해서 더 작은 맨해튼 거리를 가진 노드를 우선적으로 탐색한다. 예를 들어, 이 알고리즘이 미로에서 특정 지점에 도달하기 위해 경로를 결정할 때, 실험적으로 목표까지의 가까운 거리를 보여주는 노드를 선택한다. 그러나 GBFS는 최적의 경로를 보장하지 않는다; 일부 경우에는 최적보다 긴 경로를 선택할 수도 있다. 이러한 문제를 해결하기 위해, 이 알고리즘의 목표는 휴리스틱을 사용해서 더 나은 결정을 내리고 상태 공간의 전체적인 탐색을 줄이는 것이지만, 동시에 알고리즘의 최적성을 달성하도록 수정하는 것이다. 알고리즘의 개선을 위해서는 경로를 따라 휴리스틱 수치가 증가하는 경우를 확인하고, 조건에 따라 더 적은 단계를 요구하는 경로를 선택하여 최적의 결과를 도출할 수 있는 방법을 고려해야 한다.",
            "timestamp": "002313",
            "summarization": "탐색 알고리즘에는 다양한 유형이 있는데, 목표까지의 정확한 거리를 알지 못하며, 대신 목표까지의 예상 거리를 제공하는 휴리스틱 함수, 즉 h(n)을 사용하여 추정한다고 하며 이 문제를 해결하기 위해, 이 목표는 휴리스틱을 사용해서 더 나은 결정을 내리고 상태 공간의 전체적인 탐색을 줄이는 것이지만, 동시에 알고리즘의 최적성을 달성하도록 수정하는 것이다."
        },
        {
            "id": "test7",
            "text": "A-star 탐색 알고리즘은 휴리스틱뿐만 아니라 특정 상태에 도달하기까지의 경로 길이도 고려하여 문제를 해결한다. 이 알고리즘은 노드에 도달하는데 필요한 비용(g(n))과 목표까지의 추정 거리(h(n))의 합이 최소가 되는 노드를 확장함으로써 작동한다. g(n)은 해당 노드에 도달하기까지 걸린 단계 수를, h(n)은 문제에 따라 달라지는 휴리스틱 추정치를 나타낸다. A-star 알고리즘은 두 가지 정보, 즉 현재 위치에서 목표까지 예상되는 거리뿐만 아니라 그 위치에 도달하기까지 이동한 거리도 함께 고려한다. 이 알고리즘의 핵심은 g(n)과 h(n)의 합이 최소인 경로를 선택함으로써 최적의 해결책을 찾는 것이다. 이를 위해 A-star 탐색은 휴리스틱이 접근 가능하고 일관성이 있는 경우, 즉 실제 비용을 과대 평가하지 않고 모든 단계에서 후속 노드의 휴리스틱 가치가 현재 노드의 휴리스틱 가치와 그 노드로의 단계 비용을 합한 것보다 크지 않을 때 최적의 솔루션을 찾을 수 있다. A-star 탐색은 특정 조건 하에 최적의 해를 제공하는 알고리즘이며, 사용된 휴리스틱의 품질에 따라 문제 해결의 효율성이 달라질 수 있다. 이 알고리즘은 메모리를 상당히 사용할 수 있지만, 메모리 사용을 줄이는 대안적 접근 방식과 최적화된 다른 탐색 알고리즘들도 존재한다.",
            "timestamp": "002913",
            "summarization": "A-star 탐색 알고리즘은휴리스틱뿐만 아니라 특정 상태에 도달하기까지의 경로 길이도 고려하여 문제를 해결하는데, 이 알고리즘은 노드에 도달하는데 필요한 비용(g(n))과 목표까지의 추정 거리(h(n))의 합이 최소가 되는 노드를 확장함으로써 작동하며 이 알고리즘은 메모리를 상당히 사용할 수 있지만, 메모리 사용을 줄이는 대안적 접근 방식과 최적화된 다른 탐색 알고리즘들도 존재한다."
        },
        {
            "id": "test8",
            "text": "검색 상황에서는 때때로 적대적 상황에 직면하게 되며, 이때 한 측은 스스로를 정보적으로 결정하는 에이전트로 여기고, 상대방은 반대 목표를 가지고 맞서게 된다. 가장 대표적인 예로는 '틱택토' 게임이 있는데, 여기서는 3x3 격자 위에서 X와 O가 번갈아 가며 자신의 기호를 하나의 칸에 적으며, X 또는 O가 가로, 세로, 대각선으로 3개를 연속으로 이어서 완성하게 되면 승리하게 된다. 컴퓨터는 이러한 게임에서 매우 뛰어난 성능을 보이며, 어떠한 지능적 결정이 게임 내에서 이루어지는지를 예시를 들어 설명할 수 있다. 예를 들어, X가 중앙에 첫 번째로 움직이고, O가 상단에 움직인 후 X가 어디로 움직여야 할지는 여러 가능성 중 최적의 해를 찾는 것과 관련이 있다. 최적으로 플레이하는 인공지능은 상대방의 목표와 반대되는 결정을 내리게 되며, 이는 양측이 승리를 위해 서로를 방해하는 상황으로 이어진다. 이와 같은 적대적 검색 문제를 해결하기 위해 '민맥스(Minimax)'라는 알고리즘이 사용되는데, 이는 결정적 게임에서 두 플레이어가 각각 승리를 목표로 하며 상대방의 승리를 방해하는 상황에 적합하다. 이러한 상황을 컴퓨터가 이해할 수 있도록 게임의 상태를 수치로 변환하여 평가하는 것이 필요하며, 이를 위해 각 게임 결과에 대해 특정한 값을 할당하고, X 플레이어와 O 플레이어 각각을 최대화, 최소화 플레이어로 지정하여 승리, 패배, 무승부를 수치적으로 나타낸다. 게임을 인공지능으로 구현하기 위해서는 초기 상태, 플레이어 차례를 결정하는 함수, 가능한 행동, 상태 변환 모델, 게임 종료 여부를 판단하는 터미널 테스트, 그리고 터미널 상태의 수치적 가치를 결정하는 유틸리티 함수 등이 필요하다.",
            "timestamp": "003013",
            "summarization": "컴때로 적대적 상황에 직면하게 되는 게임에서는 '민맥스(Minimax)'라는 알고리즘을 사용해 게임의 상태를 수치로 변환하여 평가하는 것이 필요하며, 게임 결과에 대해 특정한 값을 할당하고, X 플레이어와 O 플레이어 각각을 최대화, 최소화 플레이어로 지정하여 승리, 패배, 무승부를 수치적으로 나타낸다."
        },
        {
            "id": "test9",
            "text": "검색 과정에서 사용되는 배열 또는 이차원 배열 같은 구조로 가능한 모든 사각형을 시각적으로 나타내지만, 이는 실제로 상태에 대한 배열일 뿐입니다. 플레이어 함수는 현재 상태를 바탕으로 누구의 차례인지를 알려주며, X가 첫 번째로 움직인다고 가정할 때, 비어있는 게임 보드에서는 X를 반환하고, X가 움직임을 취한 게임 보드에서는 O를 반환합니다. 행동 함수는 현재 상태에서 취할 수 있는 모든 가능한 행동의 집합을 제공합니다. 상태 전환 모델은 특정 상태에서 행동을 취했을 때 새로운 상태가 무엇인지를 정의합니다. 이는 결과 함수를 사용하여 정의되며, 미니맥스 알고리즘은 최적의 점수를 추구하는 X와 점수를 최소화하려는 O 사이에서 최상의 움직임을 결정하기 위해 사용됩니다. 게임이 종료되었는지 여부를 판단하는 기능도 구현되어야 하며, 게임의 최종 상태의 가치를 알려주는 유틸리티 함수도 필요합니다. 이러한 모든 구성 요소는 인공 지능에게 틱택토 게임의 룰을 가르치고, 게임의 가능한 모든 상태와 그 상태들 사이의 전환이 어떻게 이루어지는지를 이해하도록 합니다. 최종적으로, 인공 지능은 미니맥스 알고리즘을 사용하여 게임의 각 상태에 대해 최적의 움직임을 결정하고, 이 과정을 재귀적으로 반복하여 최종적으로는 게임의 승패를 예측합니다.",
            "timestamp": "004313",
            "summarization": "인인 지능에게 틱택토 게임의 룰을 가르치고, 게임의 가능한 모든 상태와 그 상태들 사이의 전환이 어떻게 이루어지는지를 이해하도록 하는 미니맥스 알고리즘을 사용하여 게임의 각 상태에 대해 최적의 움직임을 결정하고, 이 과정을 재귀적으로 반복하여 최종적으로는 게임의 승패를 예측합니다."
        },
        {
            "id": "test10",
            "text": "게임 복잡성 증가에 따른 연산량 및 최적화 전략에 관한 분석은, 복잡성이 증가하면 이동 가능성 및 옵션이 증가하여 게임이 길어지고 해결하는데 더 많은 시간과 공간이 필요하게 됨을 밝힌다. 이에 따라, 연산 최적화 방법에 대한 논의가 이루어지며, 특정 예시를 통해 Max 플레이어가 자신의 점수를 최대화하는 전략을 소개한다. 이 과정에서 Min 플레이어가 자신의 점수를 최소화하려고 하는 상대적 접근을 고려하고, 이에 따른 계산 과정에서의 최적화를 탐색한다. 또한, 이러한 접근을 단순화하기 위해 Alpha-Beta Pruning 기법이 도입되며, 이는 불필요한 노드를 제거함으로써 검색 효율성을 높이는 방법으로 설명된다. 더 나아가, 간단한 게임인 Tic-tac-toe와 비교하여 체스와 같은 복잡한 게임의 가능한 게임 수를 예시로 들어, Minimax 알고리즘의 한계와 이를 해결하기 위한 효율적 검색 방법의 필요성을 강조한다. 체스 게임의 초기 단계에서만 2880억 가지의 가능한 게임이 존재할 수 있으며, 이는 전체 체스 게임의 수가 10의 29,000승 이상에 이르를 수 있음을 예로 들어, 이러한 복잡성을 처리하기 위해서는 더욱 효율적인 연산 방법이 요구됨을 설명한다.",
            "timestamp": "004513",
            "summarization": "게임 복잡성 증가에 따른 연산량 및 최적화 전략에 관한 분석은, 게임 복잡성이 증가하면 이동 가능성 및 옵션이 증가하여 게임이 길어지고 해결하는데 더 많은 시간과 공간이 필요하게 됨을 밝히며 연산 최적화 방법에 대한 논의가 이루어지며, 특정 예시를 통해 Max 플레이어가 자신의 점수를 최대화하는 전략을 소개한다."
        },
        {
            "id": "test11",
            "text": "문제 해결을 위해 컴퓨터가 모든 상태를 검토하는 것은 실행 불가능하므로, 일반적으로 깊이 제한된 미니맥스라고 불리는 더 나은 접근법을 사용한다. 기존의 미니맥스가 무제한 깊이로 계속 진행되는 반면, 깊이 제한된 미니맥스는 특정 수의 수를 보고 나서, 예를 들어 10회 혹은 12회 이동을 예측한 후 추가적인 수를 고려하지 않고 정지한다. 계산상 모든 가능한 옵션을 고려하는 것은 실행 불가능하기 때문이다. 그러나 10회 또는 12회 이동 후 게임이 종료되지 않은 상태에 도달하면, 미니맥스는 여전히 게임 보드나 상태에 점수를 할당할 방법이 필요하다. 이를 위해 평가 함수라고 불리는 추가 기능을 깊이 제한된 미니맥스에 추가하여, 주어진 상태에서 게임의 예상 유틸리티를 추정하는 것이다. 예를 들어, 체스 게임에서 1의 게임 값은 백이 이기고, -1은 흑이 이기며, 0은 무승부를 의미한다면, 0.8의 점수는 백이 이길 확률이 매우 높다는 것을 의미하며, 평가 함수는 게임 상태의 좋음을 추정한다. 평가 함수의 정확성에 따라 AI의 성능이 결정되며, 평가 함수가 게임 상태의 좋고 나쁨을 얼마나 잘 추정하는지에 따라 AI가 해당 게임을 더 잘 플레이할 수 있다. 체스에서는 가능한 상황을 고려하여 상대방과 비교한 자신의 말 수를 기반으로 평가 함수를 작성할 수 있다. 깊이 제한된 미니맥스에 추가 기능을 도입하는 여러 변형은 모든 가능한 수를 탐색할 수 없는 더 크고 계산상 불가능한 상황에서 성능을 향상시키기 위해 도입되었다. 평가 함수와 기타 기술을 사용하여 이러한 게임을 더 잘 플레이하는 방법을 찾아야 한다. 이는 적대적 검색, 즉 어떤 상대와 대결하며 결정을 내리려는 인공지능이 직면하는 검색 문제의 일종으로, 인공지능 전체에서 다양한 곳에서 발견된다. 다음 시간에는 인공지능이 정보를 어떻게 알고, 그 정보에 대해 어떻게 추론하며, 결론을 도출하는지에 대한 지식을 살펴볼 것이다.",
            "timestamp": "005013",
            "summarization": "문제의 해결을 위해 컴퓨터가 모든 상태를 검토하는 것은 실행 불가능하므로, 평가 함수라고 불리는 추가 기능을 깊이 제한된 미니맥스에 추가하여, 주어진 상태에서 게임의 예상 유틸리티를 추정하는 평가 함수라고 불리는 추가 기능을 깊이 제한된 미니맥스에 추가하여, 주어진 상태에서 게임의 예상 유틸리티를 추정하는 등 여러 변형은 모든 가능한 수를 탐색할 수 없는 더 크고 계산상 불가능한 상황에서 성능을 향상시키기 위해 도입되었다."
        }
    ]
}